{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiS0z1UxWgyt"
      },
      "outputs": [],
      "source": [
        "!pip install llama_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1DwVkHCNDgT"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1_IZvrVM_FQ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkjVukvQO_5D"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NhqQz6OWDI1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f587d2fd-eb7f-47e3-8a42-c2fbe3bbd352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/278.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/278.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j"
      ],
      "metadata": {
        "id": "xfxMfnhiai65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc973d7-c641-4809-c947-d47743c39391"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neo4j\n",
            "  Downloading neo4j-5.16.0.tar.gz (197 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.8/197.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2023.3.post1)\n",
            "Building wheels for collected packages: neo4j\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neo4j: filename=neo4j-5.16.0-py3-none-any.whl size=273811 sha256=bf64111e2adc90526234ce8a6985ebd499b1042cdac352686ae36dd44304e405\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/a0/f6/87a1ec9636c915fe2d6c6e859fd55a6231dd9bc95a1d5394b1\n",
            "Successfully built neo4j\n",
            "Installing collected packages: neo4j\n",
            "Successfully installed neo4j-5.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "quYBhKouOIxM"
      },
      "outputs": [],
      "source": [
        "from llama_index.readers import BeautifulSoupWebReader\n",
        "from llama_index import (\n",
        "    SimpleDirectoryReader,\n",
        "    GPTVectorStoreIndex,\n",
        "    VectorStoreIndex,\n",
        "    ServiceContext,\n",
        "    download_loader,\n",
        "    PromptHelper,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        "    StorageContext,\n",
        "    KnowledgeGraphIndex,\n",
        "    load_graph_from_storage\n",
        ")\n",
        "from llama_index.query_engine import KnowledgeGraphQueryEngine\n",
        "from llama_index.graph_stores import Neo4jGraphStore, NebulaGraphStore\n",
        "from llama_index.embeddings import HuggingFaceEmbedding, OpenAIEmbedding, LangchainEmbedding\n",
        "from llama_index.response.notebook_utils import display_response\n",
        "from llama_index.graph_stores import SimpleGraphStore\n",
        "from llama_index.vector_stores import ChromaVectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Hk4adwL0mp6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f05f0e-623b-443d-eed5-dedf58be3d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.27.tar.gz (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.9.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.27-cp310-cp310-manylinux_2_35_x86_64.whl size=8182245 sha256=80f2c5eedc25573fa6c41f8079c4b6c12771d8c67546c77c36cfad8fdc20e2cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/92/37/ada3fcfdf537bab790219920443164923e6cbfcbd80174af23\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: llama-cpp-python\n",
            "Successfully installed llama-cpp-python-0.2.27\n"
          ]
        }
      ],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python\n",
        "from llama_index.llms import LlamaCPP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMNaHDzPM68f",
        "outputId": "eacd3633-66ae-432a-94ba-8114abf1aea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading url https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q5_K_M.gguf?download=true to path /tmp/llama_index/models/mistral-7b-instruct-v0.2.Q5_K_M.gguf?download=true\n",
            "total size (MB): 5131.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4894it [00:32, 149.52it/s]                          \n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from llama_index.prompts import PromptTemplate\n",
        "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
        "from llama_index.llms import HuggingFaceLLM\n",
        "from llama_index.llms.llama_utils import (\n",
        "    messages_to_prompt,\n",
        "    completion_to_prompt,\n",
        ")\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "import logging\n",
        "import sys\n",
        "import os\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
        "callback_manager = CallbackManager([llama_debug])\n",
        "model_url = \"https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q5_K_M.gguf?download=true\"\n",
        "\n",
        "# Change LLMs and see different !!!\n",
        "\n",
        "llm = LlamaCPP(model_url=model_url, model_path=None,\n",
        "    temperature=0.1,\n",
        "    max_new_tokens=256,\n",
        "    model_kwargs={\"n_gpu_layers\": 60},\n",
        "    callback_manager = callback_manager,\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        "    completion_to_prompt=completion_to_prompt,\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_url = \"https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q5_K_M.gguf?download=true\"\n",
        "\n",
        "# Change LLMs and see different !!!\n",
        "\n",
        "llm_phi = LlamaCPP(model_url=model_url, model_path=None,\n",
        "    temperature=0.1,\n",
        "    max_new_tokens=256,\n",
        "    model_kwargs={\"n_gpu_layers\": 60},\n",
        "    callback_manager = callback_manager,\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        "    completion_to_prompt=completion_to_prompt,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei7duXSIqDVD",
        "outputId": "fdb3e9bb-65a5-48fe-f3ec-c8930779e4c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading url https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q5_K_M.gguf?download=true to path /tmp/llama_index/models/phi-2.Q5_K_M.gguf?download=true\n",
            "total size (MB): 2072.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1977it [00:15, 129.49it/s]\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from llama_index import download_loader\n",
        "\n",
        "PDFReader = download_loader(\"PDFReader\")\n",
        "\n",
        "loader = PDFReader()\n",
        "documents = loader.load_data(file=Path('/content/Employment-Manual-January-2023-trang-1.pdf'))"
      ],
      "metadata": {
        "id": "iE4hBNvnrahX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "<s><INST> ## 1. Overview\n",
        "You are a top-tier algorithm designed for extracting information about a guide for employees who want to understand labor laws in structured formats to build a knowledge graph.\n",
        "- **Nodes** represent entities and concepts. They're akin to Wikipedia nodes.\n",
        "- The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible for a vast audience.\n",
        "## 2. Labeling Nodes\n",
        "- **Consistency**: Ensure you use basic or elementary types for node labels.\n",
        "  - For example, when you identify an entity representing a person, always label it as **\"person\"**. Avoid using more specific terms like \"mathematician\" or \"scientist\".\n",
        "- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\n",
        "## 3. Handling Numerical Data and Dates\n",
        "- Numerical data, like age or other related information, should be incorporated as attributes or properties of the respective nodes.\n",
        "- **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.\n",
        "- **Property Format**: Properties must be in a key-value format.\n",
        "- **Quotation Marks**: Never use escaped single or double quotes within property values.\n",
        "- **Naming Convention**: Use camelCase for property keys, e.g., `birthDate`.\n",
        "## 4. Coreference Resolution\n",
        "- **Maintain Entity Consistency**: When extracting entities, it's vital to ensure consistency.\n",
        "If an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),\n",
        "always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\n",
        "Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\n",
        "## 5. Strict Compliance\n",
        "Adhere to the rules strictly.Do not contain any explanations or appologies in your response.Non-compliance will result in termination.\n",
        "\n",
        "Example:\n",
        " \"Some text is provided below. Given the text, extract up to \"\n",
        "    \"{max_knowledge_triplets} \"\n",
        "    \"knowledge triplets in the form of (subject, predicate, object). Avoid stopwords.\\n\"\n",
        "    \"---------------------\\n\"\n",
        "    \"Example:\"\n",
        "    \"Text: Alice is Bob's mother.\"\n",
        "    \"Triplets:\\n(Alice, is mother of, Bob)\\n\"\n",
        "    \"Text: Philz is a coffee shop founded in Berkeley in 1982.\\n\"\n",
        "    \"Triplets:\\n\"\n",
        "    \"(Philz, is, coffee shop)\\n\"\n",
        "    \"(Philz, founded in, Berkeley)\\n\"\n",
        "    \"(Philz, founded in, 1982)\\n\"\n",
        "    \"---------------------\\n\"\n",
        "    \"Text: {text}\\n\"\n",
        "    \"Triplets:\\n\"\n",
        " </INST>\n",
        "\"\"\"\n",
        "prompt_template = PromptTemplate(prompt, prompt_type = \"knowledge_triplet_extract\")"
      ],
      "metadata": {
        "id": "5DTRDsj-BEen"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH7NxhrOjdMT"
      },
      "outputs": [],
      "source": [
        "#embed_model = OpenAIEmbedding() #sentence-transformers/all-roberta-large-v1\n",
        "embed_model = LangchainEmbedding(HuggingFaceEmbedding(\"sentence-transformers/all-roberta-large-v1\")) #local:BAAI/bge-small-en-v1.5\n",
        "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model, chunk_size = 128, chunk_overlap = 120)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "service_context_phi = ServiceContext.from_defaults(llm=llm_phi, embed_model=embed_model, chunk_size = 128, chunk_overlap = 120)"
      ],
      "metadata": {
        "id": "e8cGqs8Mqg2c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "username = \"neo4j\"\n",
        "password = \"7q0G7tP_ZxJGK-HH87pNoLMqcCO4sDN2cQnPIASwzLw\"\n",
        "url = \"neo4j+s://39992655.databases.neo4j.io\"\n",
        "database = \"neo4j\""
      ],
      "metadata": {
        "id": "x0Q6GqKeyEOQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_store = Neo4jGraphStore(\n",
        "    username=username,\n",
        "    password=password,\n",
        "    url=url,\n",
        "    database=database,\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
      ],
      "metadata": {
        "id": "dR8zObDS3Z45"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_3MBGDZS7gfl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bc07fe2fe7514eab8f6591db6d06f6c0",
            "c65eff95cda24518aee80f42d12441fb",
            "9a8b0b5e3e0a4f2cbc6092bcc8bd1551",
            "99f2ab9f09d54022a759bc7743232162",
            "794848d20fc9467db1a4a4e1a0a2bd84",
            "58a49abea1e64901a4d42a6f29c18d61",
            "8c416adfc7714490a0d1e8c927112e25",
            "32c9d0d152e94a51aa41c917c38928b0",
            "dec1838548714e47b36ac032058899a3",
            "65f1158696474d48b08590eced9207fa",
            "3951d73082f743f0a1fea12fea138a6e",
            "047072cb397048cf89a76ce84780b2fc",
            "0fd064360c9542058ea41f1e2621cef1",
            "d0f7336759e147ff9efe8490771eeefa",
            "e0fb10619ec344f0a74130ffb943e18b",
            "54966b8000b44d9fbafd8c9eba7701d9",
            "f39d94b841d3474497393bbd44efd98b",
            "d06dbabf4302401d8b4a638287fca360",
            "27dafa4c5c1548dc83c0e457770e2dbc",
            "f12b8cdd425842a49cc2ebdfd6344f9f",
            "c055f714826a478bb2a1caa330046873",
            "a2e8d6f1b314416abbb7d81e394c66e0"
          ]
        },
        "outputId": "1894713b-31cf-4a5d-de49-c884f92dedac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc07fe2fe7514eab8f6591db6d06f6c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing nodes:   0%|          | 0/262 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "047072cb397048cf89a76ce84780b2fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n"
          ]
        }
      ],
      "source": [
        "index = KnowledgeGraphIndex.from_documents(\n",
        "    documents,\n",
        "    storage_context=storage_context,\n",
        "    max_triplets_per_chunk=10,\n",
        "    #kg_triplet_extract_fn=extract_triplets,\n",
        "    service_context=service_context,\n",
        "    kg_triple_extract_template=prompt_template,\n",
        "    #include_embedding = True,\n",
        "    show_progress = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    include_text=False,\n",
        "    response_mode=\"tree_summarize\", #test response !!!\n",
        "    #embedding_mode=\"hybrid\", #\n",
        "    similarity_top_k=5,\n",
        "    #explore_global_knowledge=True\n",
        ")"
      ],
      "metadata": {
        "id": "GzhW1axc0y_6"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOt5I-DxokMk",
        "outputId": "20797205-2532-4e78-d1d6-a2e224ebc7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "WARNING:llama_index.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index was not constructed with embeddings, skipping embedding usage...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        }
      ],
      "source": [
        "query_str = \"According to labor code tell me about DOLISA ?\"\n",
        "response = query_engine.query(query_str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "OFHOEFB29lHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuSIu9MlJfK9",
        "outputId": "e167cf39-f5f9-49aa-848e-6ac0a86bc130"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " DOLISA, which stands for \"Department of Labor, Invalids and Social Affairs,\" is an organization that is responsible for various tasks related to labor and employment issues in Vietnam. It is a subset of the Ministry of Labor, Invalids and Social Affairs (MOLISA).\n",
            "\n",
            "According to the given information, DOLISA can confirm work permit exemptions for employers and expatriates. Employers must file an application with DOLISA to confirm work permit exemptions for their expatriate employees. Additionally, expatriates must meet certain conditions, such as being in good health, of full age (18 years or older), not being subject to prosecution, and working as a manager/general director or chief representative, expert, or technician, among other things.\n",
            "\n",
            "Furthermore, DOLISA is the organization that issues legal documents related to labor and employment. It also ensures compliance with national policies on employment and provides guidance concerning these policies.\n",
            "\n",
            "It's important to note that while DOLISA plays a significant role in labor and employment matters, it operates under the People’s Committee, which determines sufficient demand for expatriate employment and provides regulations on the labor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvis"
      ],
      "metadata": {
        "id": "VCUiVU25CTOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db22f54c-6139-4b46-b600-afe9cbd2323f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.1.2)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.0.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis) (2.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.12)\n",
            "Installing collected packages: jedi, pyvis\n",
            "Successfully installed jedi-0.19.1 pyvis-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvis.network import Network\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "g = index.get_networkx_graph()\n",
        "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
        "net.from_nx(g)\n",
        "net.show(\"example.html\")\n",
        "\n",
        "display(HTML(filename=\"example.html\"))"
      ],
      "metadata": {
        "id": "0olSfmvhCSfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "net.show(\"example.html\")\n",
        "display(IFrame(\"example.html\", width=800, height=600))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zBD9FEOBG2rL",
        "outputId": "30237ed6-a0b4-48eb-d202-a4983a543214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example.html\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7a04247f3b50>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"600\"\n",
              "            src=\"example.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.storage_context.persist(persist_dir = './content/graph_chatbot') #save index"
      ],
      "metadata": {
        "id": "GbBN51hrx5L2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/content/graph_chatbot.zip /content/content/graph_chatbot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wvt569W-Xnt",
        "outputId": "34d1d0f0-f1d9-494f-9eb0-1bfd77121cb3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/content/graph_chatbot/ (stored 0%)\n",
            "  adding: content/content/graph_chatbot/default__vector_store.json (deflated 19%)\n",
            "  adding: content/content/graph_chatbot/index_store.json (deflated 84%)\n",
            "  adding: content/content/graph_chatbot/docstore.json (deflated 88%)\n",
            "  adding: content/content/graph_chatbot/image__vector_store.json (deflated 19%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf content"
      ],
      "metadata": {
        "id": "vKnEg1FcIIar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storage_graph = StorageContext.from_defaults(persist_dir = './content/graph_chatbot',graph_store = graph_store)"
      ],
      "metadata": {
        "id": "fpQqSO6-Gl19"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg_index = load_index_from_storage(\n",
        "    storage_context = storage_graph,\n",
        "    service_context = service_context,\n",
        "    max_triplets_per_chunk = 10,\n",
        "    llm = llm\n",
        ")"
      ],
      "metadata": {
        "id": "rwDigDqaGan5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg_query_engine = kg_index.as_query_engine(\n",
        "    include_text=False,\n",
        "    response_mode=\"tree_summarize\", #test response !!!\n",
        "    #embedding_mode=\"hybrid\", #\n",
        "    similarity_top_k=5,\n",
        ")"
      ],
      "metadata": {
        "id": "Mdob3h9KBfB4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_str = \"According to labor code tell me about DOLISA\"\n",
        "response = kg_query_engine.query(query_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vihnw5f-Bk-_",
        "outputId": "060577ff-046f-4498-8b6f-7dc4291e0b7c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "WARNING:llama_index.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index was not constructed with embeddings, skipping embedding usage...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG1qZpptD9Ht",
        "outputId": "3f19aa55-6057-4f3d-e887-55291798a72d"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Based on the provided information, DOLISA (Directorate of Labor, Invalids and Social Affairs) is an organization that is a subset of MOLISA (Ministry of Labor, Invalids and Social Affairs). It can issue legal documents related to labor and employment. Employers must file an application with DOLISA for work permit exemptions for expatriates, and DOLISA confirms the exemption if the employer meets certain conditions. The document required for a work permit application includes various information about the expatriate and the employment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine_load = KnowledgeGraphQueryEngine(\n",
        "    storage_context=storage_context,\n",
        "    service_context=service_context,\n",
        "    llm=llm_phi,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "tf8Vot_Y-RgF"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.memory import ChatMemoryBuffer\n",
        "\n",
        "memory = ChatMemoryBuffer.from_defaults(token_limit=1500)\n",
        "# chat_engine = ReActAgent.from_tools(\n",
        "#     query_engine_tools, llm=llm, memory=memory, verbose=True\n",
        "# )\n",
        "\n",
        "chat_engine = kg_index.as_chat_engine(\n",
        "    chat_mode=\"react\",\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "JltPxyXE9LG4"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_engine.chat(\"According to labor code tell me about DOLISA\")"
      ],
      "metadata": {
        "id": "p1anlbQXLTvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbg6ZZwLHryA"
      },
      "source": [
        "## Compare and Combining KG Index and VectorStore Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJkl5OUvVZGc"
      },
      "outputs": [],
      "source": [
        "# import QueryBundle\n",
        "from llama_index import QueryBundle\n",
        "\n",
        "# import NodeWithScore\n",
        "from llama_index.schema import NodeWithScore\n",
        "\n",
        "# Retrievers\n",
        "from llama_index.retrievers import (\n",
        "    BaseRetriever,\n",
        "    VectorIndexRetriever,\n",
        "    KGTableRetriever,\n",
        ")\n",
        "\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class CustomRetriever(BaseRetriever):\n",
        "    \"\"\"Custom retriever that performs both Vector search and Knowledge Graph search\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vector_retriever: VectorIndexRetriever,\n",
        "        kg_retriever: KGTableRetriever,\n",
        "        mode: str = \"OR\",\n",
        "    ) -> None:\n",
        "        \"\"\"Init params.\"\"\"\n",
        "\n",
        "        self._vector_retriever = vector_retriever\n",
        "        self._kg_retriever = kg_retriever\n",
        "        if mode not in (\"AND\", \"OR\"):\n",
        "            raise ValueError(\"Invalid mode.\")\n",
        "        self._mode = mode\n",
        "        super().__init__()\n",
        "\n",
        "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "        \"\"\"Retrieve nodes given query.\"\"\"\n",
        "\n",
        "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
        "        kg_nodes = self._kg_retriever.retrieve(query_bundle)\n",
        "\n",
        "        vector_ids = {n.node.node_id for n in vector_nodes}\n",
        "        kg_ids = {n.node.node_id for n in kg_nodes}\n",
        "\n",
        "        combined_dict = {n.node.node_id: n for n in vector_nodes}\n",
        "        combined_dict.update({n.node.node_id: n for n in kg_nodes})\n",
        "\n",
        "        if self._mode == \"AND\":\n",
        "            retrieve_ids = vector_ids.intersection(kg_ids)\n",
        "        else:\n",
        "            retrieve_ids = vector_ids.union(kg_ids)\n",
        "\n",
        "        retrieve_nodes = [combined_dict[rid] for rid in retrieve_ids]\n",
        "        return retrieve_nodes"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc07fe2fe7514eab8f6591db6d06f6c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c65eff95cda24518aee80f42d12441fb",
              "IPY_MODEL_9a8b0b5e3e0a4f2cbc6092bcc8bd1551",
              "IPY_MODEL_99f2ab9f09d54022a759bc7743232162"
            ],
            "layout": "IPY_MODEL_794848d20fc9467db1a4a4e1a0a2bd84"
          }
        },
        "c65eff95cda24518aee80f42d12441fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a49abea1e64901a4d42a6f29c18d61",
            "placeholder": "​",
            "style": "IPY_MODEL_8c416adfc7714490a0d1e8c927112e25",
            "value": "Parsing nodes: 100%"
          }
        },
        "9a8b0b5e3e0a4f2cbc6092bcc8bd1551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c9d0d152e94a51aa41c917c38928b0",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dec1838548714e47b36ac032058899a3",
            "value": 12
          }
        },
        "99f2ab9f09d54022a759bc7743232162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f1158696474d48b08590eced9207fa",
            "placeholder": "​",
            "style": "IPY_MODEL_3951d73082f743f0a1fea12fea138a6e",
            "value": " 12/12 [00:00&lt;00:00, 43.94it/s]"
          }
        },
        "794848d20fc9467db1a4a4e1a0a2bd84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a49abea1e64901a4d42a6f29c18d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c416adfc7714490a0d1e8c927112e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32c9d0d152e94a51aa41c917c38928b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec1838548714e47b36ac032058899a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65f1158696474d48b08590eced9207fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3951d73082f743f0a1fea12fea138a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "047072cb397048cf89a76ce84780b2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fd064360c9542058ea41f1e2621cef1",
              "IPY_MODEL_d0f7336759e147ff9efe8490771eeefa",
              "IPY_MODEL_e0fb10619ec344f0a74130ffb943e18b"
            ],
            "layout": "IPY_MODEL_54966b8000b44d9fbafd8c9eba7701d9"
          }
        },
        "0fd064360c9542058ea41f1e2621cef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f39d94b841d3474497393bbd44efd98b",
            "placeholder": "​",
            "style": "IPY_MODEL_d06dbabf4302401d8b4a638287fca360",
            "value": "Processing nodes: 100%"
          }
        },
        "d0f7336759e147ff9efe8490771eeefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27dafa4c5c1548dc83c0e457770e2dbc",
            "max": 262,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f12b8cdd425842a49cc2ebdfd6344f9f",
            "value": 262
          }
        },
        "e0fb10619ec344f0a74130ffb943e18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c055f714826a478bb2a1caa330046873",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e8d6f1b314416abbb7d81e394c66e0",
            "value": " 262/262 [1:18:30&lt;00:00, 17.22s/it]"
          }
        },
        "54966b8000b44d9fbafd8c9eba7701d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f39d94b841d3474497393bbd44efd98b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d06dbabf4302401d8b4a638287fca360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27dafa4c5c1548dc83c0e457770e2dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f12b8cdd425842a49cc2ebdfd6344f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c055f714826a478bb2a1caa330046873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e8d6f1b314416abbb7d81e394c66e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}